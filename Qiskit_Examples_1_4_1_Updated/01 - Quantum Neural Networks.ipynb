{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad692fc-e597-4b97-940b-03a765f403d9",
   "metadata": {},
   "source": [
    "# 01 - Quantum Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63483b6e-de2f-4155-8654-a430c8323a60",
   "metadata": {},
   "source": [
    "#### Uncomment the cell below to pip install the necessary modules if not already installed\n",
    "\n",
    "#### Note: Works with Qiskit Version 1.4.1 and Quantum Rings Qiskit Toolkit Version 0.1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09774be9-234d-4886-b4d5-66de8cd081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install qiskit-machine-learning\n",
    "# %pip install qiskit==1.4.1\n",
    "# %pip install quantumrings-toolkit-qiskit==0.1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40bf48-a541-4a9d-8574-36cfe9be7322",
   "metadata": {},
   "source": [
    "#### Restart the kernel after installing any of the missing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d2056-0fa2-4247-869f-bae51e071cdd",
   "metadata": {},
   "source": [
    "#### Brief Introduction\n",
    "\n",
    "The topic of Machine Learning and Neural Networks is vast and broad in both the classical and quantum sense of the subject. Therefore, we will keep this introduction as brief as possible just to cover the main points implemented in this notebook.\n",
    "\n",
    "Classical neural networks, as one might assume, was heavily inspired by the human brain. It is an algorithmic approach that was developed based on our own ability towards pattern recognition and for solving complex problems. Similar to how children learn through repetition or by example, a neural network learns through a training process based on a specific set of data which contains patterns the network is designed to \"understand\". It is a layered structure of interconnected nodes, or neurons, that are given parameters which can be dynamically modified during the training process known as the weights. In the brain, these weights would be equivalent to the strength of the synapse connection between neurons. \n",
    "\n",
    "From a machine learning perspective, quantum neural networks, or quantum machine learning (QML) is motivated by the integration of classical neural networks and parameterized quantum circuits. The quantum neural network (QNN) is a similar algorithmic model that can be trained to find hidden patterns in data similar to the classical neural network. The models load classical data into a quantum state, and process it with quantum gates parameterized by trainable weights. The output of this state can be plugged into a loss function to train the weights through backpropagation.\n",
    "\n",
    "From a quantum computing perspective, the QNN is just a quantum algorithm based on a parameterized quantum circuit that can be trained using variational methods for parameter adjustment via classical optimizers (Gradient Descent, Linear Programming, Simulated Annealing, etc). The circuit is a combination of smaller circuits, or layers, similar to classical neural networks. It will have at least one layer of a sub-circuit that is the feature map for the input parameters followed by a second layer for data processing with variational weights. These layers can be repeated as many times as desired and will always be followed by a measurement layer at the very end of the circuit.\n",
    "\n",
    "As mentioned at the start, this is just a brief overview of both topics. There are numerous branches of both classical and quantum machine learning each with their own sub-branches into specific algorithms, approaches, applications, and so much more. For now we will stop here, and start dipping our toes into building a circuit to model a QNN using estimators and samplers.\n",
    "\n",
    "If you want to know more, please check the link below for Qiskit specific information on QML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50215983-70a5-435a-a551-ae878d46e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is at:\n",
    "# https://qiskit-community.github.io/qiskit-machine-learning/tutorials/01_neural_networks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc77a5-9aaf-452b-b7e7-ecac0a96fdd1",
   "metadata": {},
   "source": [
    "We set the seed to ensure that the results are consistent. For \"random\" results, seed with system time using the commented code in the cell. The algorithm_globals is a class for generating random values for any algorithm used when calling algorithm_globals.random. By setting a seed, we ensure repeatability. For fun, if you want something more random, comment out the answer to lifes biggest question and uncomment the import time and time.time(). This will give it a random seed based on the system time rather than a static seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91235404-f2b8-4271-8e9e-99930574a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# algorithm_globals.random_seed = time.time()\n",
    "\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "\n",
    "algorithm_globals.random_seed = 42 # The answer to lifes biggest question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b620d4-d9f5-4161-bccd-355852fb18a2",
   "metadata": {},
   "source": [
    "### Step 1: Instantiate the Quantum Circuit: EstimatorQNN vs SamplerQNN\n",
    "There are two ways we can approach the implementation of a QNN. We have an EstimatorQNN and a SamplerQNN. They are similar in their creation with some minor variations. Ultimately, their functionality differ in that the EstimatorQNN is based on the network evaluation of quantum mechanical observables. The SamplerQNN is based on the samples resulting from measuring a quantum circuit. These will be elaborated upon in their respective sections.\n",
    "#### Step 1a: EstimatorQNN\n",
    "The EstimatorQNN takes in a parameterized quantum circuit as input along with optional quantum mechanical observables, and outputs expectation value computations for the forward pass. We can also give the estimator a list of observables for more complex circuits. First we will construct a simple circuit with two parameters, one as the QNN input and the other as a trainable weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf149db3-c1a7-44ea-b414-9ec372bb522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "params1 = [Parameter(\"input1\"), Parameter(\"weight1\")]\n",
    "qc1 = QuantumCircuit(1)\n",
    "qc1.h(0)\n",
    "qc1.ry(params1[0], 0)\n",
    "qc1.rx(params1[1], 0)\n",
    "qc1.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad8cdc-e124-48f4-8d99-539e25e613f0",
   "metadata": {},
   "source": [
    "We create the observable below to define the expectation value computation. If this is not set, then the estimator will automatically create a default observable $Z^{\\otimes n}$. Here, $n$ is the number of qubits in the quantum circuit. For the observable we create below, we set the observable as $Y^{\\otimes n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca064a6-671b-42e4-8cb7-47593145e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "observable1 = SparsePauliOp.from_list([(\"Y\" * qc1.num_qubits, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1e2a2-fc0d-45f7-969e-08b1587bfa8e",
   "metadata": {},
   "source": [
    "Now that we have our circuit and observable, we want to instantiate the EstimatorQNN. The constructor for this takes four key arguments:\n",
    "\n",
    "- `estimator`: optional primitive instance\n",
    "- `pass_manager`: optional pass_manager instance for primitives that require transpilation\n",
    "- `input_params`: list of quantum circuit parameters that should be treated as \"network inputs\"\n",
    "- `weight_params`: list of quantum circuit parameters that should be treated as \"network weights\"\n",
    "\n",
    "Based on our definition above, the first parameter of params1 is our input_params, and the second parameter is our weight_params. We do not define an estimator, this will cause the EstimatorQNN to create an instance of the base Estimator. The pass_manager is only necessary if the circuit needs to be transpiled which is not necessary for our current purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb46f17-99be-492e-ac0a-88c1637286af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the toolkit, we can implement the EstimatorQNN\n",
    "from quantumrings.toolkit.qiskit.machine_learning import QrEstimatorQNN as EstimatorQNN\n",
    "\n",
    "estimator_qnn = EstimatorQNN(\n",
    "    circuit=qc1, observables=observable1, input_params=[params1[0]], weight_params=[params1[1]]\n",
    ")\n",
    "# This concludes the creation of our  EstimatorQNN. Next we will look at the SamplerQNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f962749-8f2e-4993-b8a6-a0eb76c8c3f0",
   "metadata": {},
   "source": [
    "#### Step 1b: SamplerQNN\n",
    "\n",
    "The SamplerQNN is created in a similar manner as the EstimatorQNN. The major difference lies in the sampler consuming samples from measuring the quantum circuit. This means it does not require a custom observable. The output samples are interpreted by default as the probabilities of measuring the integer index corresponding to a bitstring. We can also specify an interpret function to post-process the samples. This function should be defined so that it takes a measured integer from a bitstring and maps it to a new value, i.e. non-negative integer\n",
    "\n",
    "If a custom interpret function is defined, the output_shape cannot be inferred by the network and needs to be provided explicitly.\n",
    "\n",
    "If no interpret function is used, the dimension of the probability vector scales exponentially with the number of qubits. With a custom interpret function, this scaling can change.\n",
    "\n",
    "We will create a different quantum circuit for the SamplerQNN. We will have two input parameters and four trainable weights that parameterize a two-local circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633d938-f2dc-44da-83bb-d02a2dd67eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "inputs2 = ParameterVector(\"input\", 2)\n",
    "weights2 = ParameterVector(\"weight\", 4)\n",
    "print(f\"input parameters: {[str(item) for item in inputs2.params]}\")\n",
    "print(f\"weight parameters: {[str(item) for item in weights2.params]}\")\n",
    "\n",
    "qc2 = QuantumCircuit(2)\n",
    "qc2.ry(inputs2[0], 0)\n",
    "qc2.ry(inputs2[1], 1)\n",
    "qc2.cx(0, 1)\n",
    "qc2.ry(weights2[0], 0)\n",
    "qc2.ry(weights2[1], 1)\n",
    "qc2.cx(0, 1)\n",
    "qc2.ry(weights2[2], 0)\n",
    "qc2.ry(weights2[3], 1)\n",
    "\n",
    "qc2.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a20f5-052d-477f-81b3-b7899270a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the toolkit, we can implement the SamplerQNN as we did the EstimatorQNN before. \n",
    "# The key parameters for the SamplerQNN are the same as the EstimatorQNN defined above.\n",
    "\n",
    "from quantumrings.toolkit.qiskit.machine_learning import QrSamplerQNN as SamplerQNN\n",
    "\n",
    "sampler_qnn = SamplerQNN(circuit=qc2, input_params=inputs2, weight_params=weights2)\n",
    "sampler_qnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eedfe8-6fb5-4635-bd81-ea0b75129b80",
   "metadata": {},
   "source": [
    "### Step 2: Run a Forward Pass\n",
    "\n",
    "In it's most basic form, a forward pass is just a run through the neural network. Each input is passed through each layer and produces an output. Here we create random inputs and weights for the estimator and sampler using the algorithm_globals which we seeded at the start. \n",
    "\n",
    "First, we will run both the estimator and the sampler in a non-batched form. This form means that we just give it all the inputs we have for the circuit. We will follow this up with a batched forward pass. Look at how the outputs and shapes of the returned values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa46a50-de5f-455c-9585-7217acaf03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_input = algorithm_globals.random.random(estimator_qnn.num_inputs)\n",
    "estimator_qnn_weights = algorithm_globals.random.random(estimator_qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662aed62-cc8d-4b5c-bfda-ee5ed4a5652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of input features for EstimatorQNN: {estimator_qnn.num_inputs} \\nInput: {estimator_qnn_input}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of trainable weights for EstimatorQNN: {estimator_qnn.num_weights} \\nWeights: {estimator_qnn_weights}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64200b30-9c79-438a-a2f6-6e7d1ccd61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_input = algorithm_globals.random.random(sampler_qnn.num_inputs)\n",
    "sampler_qnn_weights = algorithm_globals.random.random(sampler_qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e3f47-09a8-4276-b3a4-2393a77e9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of input features for SamplerQNN: {sampler_qnn.num_inputs} \\nInput: {sampler_qnn_input}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of trainable weights for SamplerQNN: {sampler_qnn.num_weights} \\nWeights: {sampler_qnn_weights}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac41217-fe97-410e-8f5e-6b0ce056f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_forward = estimator_qnn.forward(estimator_qnn_input, estimator_qnn_weights)\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for EstimatorQNN: {estimator_qnn_forward}. \\nShape: {estimator_qnn_forward.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca605bf-fed4-42a3-86bc-e304b1dda899",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_forward = sampler_qnn.forward(sampler_qnn_input, sampler_qnn_weights)\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for SamplerQNN: {sampler_qnn_forward}.  \\nShape: {sampler_qnn_forward.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65151d6b-499b-489b-b664-fad2e35ae617",
   "metadata": {},
   "source": [
    "#### Now we batch the inputs. This is done by passing in a list of the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89fc64-972b-4e7a-bf03-b41ad11944bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_forward_batched = estimator_qnn.forward(\n",
    "    [estimator_qnn_input, estimator_qnn_input], estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for EstimatorQNN: {estimator_qnn_forward_batched}.  \\nShape: {estimator_qnn_forward_batched.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35344c1-c025-4d03-983b-f9da52149c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_forward_batched = sampler_qnn.forward(\n",
    "    [sampler_qnn_input, sampler_qnn_input], sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Forward pass result for SamplerQNN: {sampler_qnn_forward_batched}.  \\nShape: {sampler_qnn_forward_batched.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9ef7c-ec7e-49f6-963d-a094785a91f4",
   "metadata": {},
   "source": [
    "#### While a forward pass may be good for some cases, sometimes we wish to know how the network evolves\n",
    "\n",
    "By default, the backward pass uses gradient descent to look at how the weights change as the input is propagated through the network. You can enable gradients for the input parameters by setting the attribute input_gradients=True for each of the QNNs. We initially show the result without an input gradient, and then with an input gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5bec1-7d5f-4182-a45d-132dae7a56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_input_grad, estimator_qnn_weight_grad = estimator_qnn.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for EstimatorQNN: {estimator_qnn_input_grad}.  \\nShape: {estimator_qnn_input_grad}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for EstimatorQNN: {estimator_qnn_weight_grad}.  \\nShape: {estimator_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebec98-c40d-442d-a499-0c57149e55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_input_grad, sampler_qnn_weight_grad = sampler_qnn.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for SamplerQNN: {sampler_qnn_input_grad}.  \\nShape: {sampler_qnn_input_grad}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for SamplerQNN: {sampler_qnn_weight_grad}.  \\nShape: {sampler_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7aa4d-0487-4d38-92e2-8fab13852d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn.input_gradients = True\n",
    "sampler_qnn.input_gradients = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e4b90-1861-4e64-88bd-e29272e28bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_input_grad, estimator_qnn_weight_grad = estimator_qnn.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for EstimatorQNN: {estimator_qnn_input_grad}.  \\nShape: {estimator_qnn_input_grad.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for EstimatorQNN: {estimator_qnn_weight_grad}.  \\nShape: {estimator_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f7103-380c-4aaf-8340-f0399e4f606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_input_grad, sampler_qnn_weight_grad = sampler_qnn.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Input gradients for SamplerQNN: {sampler_qnn_input_grad}.  \\nShape: {sampler_qnn_input_grad.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"Weight gradients for SamplerQNN: {sampler_qnn_weight_grad}.  \\nShape: {sampler_qnn_weight_grad.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63162920-18dc-4b5e-a62b-e4b9221125c5",
   "metadata": {},
   "source": [
    "### Step 3: Advanced Functionality: Multiple Observables with EstimatorQNN, Custom Interpret with SamplerQNN\n",
    "\n",
    "For more complex QNN architectures, we can pass in a list of observables to the EstimatorQNN. Below we create a second observable for $Z^{\\otimes n}$ to include in the estimator. We then carry out a forward and backward, non-batched run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de3cf8-a576-4f17-98e6-1fe35ad94d56",
   "metadata": {},
   "source": [
    "### Multiple Observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7db8b7-9e82-4f3d-a72b-bb07bef9a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observable2 = SparsePauliOp.from_list([(\"Z\" * qc1.num_qubits, 1)])\n",
    "\n",
    "estimator_qnn2 = EstimatorQNN(\n",
    "    circuit=qc1,\n",
    "    observables=[observable1, observable2],\n",
    "    input_params=[params1[0]],\n",
    "    weight_params=[params1[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185761d-e420-4042-9686-1e36175ebb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn_forward2 = estimator_qnn2.forward(estimator_qnn_input, estimator_qnn_weights)\n",
    "estimator_qnn_input_grad2, estimator_qnn_weight_grad2 = estimator_qnn2.backward(\n",
    "    estimator_qnn_input, estimator_qnn_weights\n",
    ")\n",
    "\n",
    "print(f\"Forward output for EstimatorQNN1: {estimator_qnn_forward.shape}\")\n",
    "print(f\"Forward output for EstimatorQNN2: {estimator_qnn_forward2.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN1: {estimator_qnn_weight_grad.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN2: {estimator_qnn_weight_grad2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80882d1e-7618-4af9-a974-fbe2c1f42e08",
   "metadata": {},
   "source": [
    "### Custom Interpreter\n",
    "\n",
    "As mentioned above, we can give the SamplerQNN a custom interpreter for measuring the integer index of the bitstring. Here we use a lambda function to define our interpreter. This will use a parity method, which allows it to perform binary classification. This will modify the output shape of the forward and backward passes. Feel free to modify this cell to use the parity function and use just the default interpret. Think about the differences of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c50df-7efa-46d4-b963-8ab7a01a8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parity = lambda x: \"{:b}\".format(x).count(\"1\") % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "sampler_qnn2 = SamplerQNN(\n",
    "    circuit=qc2,\n",
    "    input_params=inputs2,\n",
    "    weight_params=weights2,\n",
    "    interpret=parity,\n",
    "    output_shape=output_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b37a2-58bd-4ec3-ad55-6acec6a9d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_qnn_forward2 = sampler_qnn2.forward(sampler_qnn_input, sampler_qnn_weights)\n",
    "sampler_qnn_input_grad2, sampler_qnn_weight_grad2 = sampler_qnn2.backward(\n",
    "    sampler_qnn_input, sampler_qnn_weights\n",
    ")\n",
    "\n",
    "print(f\"Forward output for SamplerQNN1: {sampler_qnn_forward.shape}\")\n",
    "print(f\"Forward output for SamplerQNN2: {sampler_qnn_forward2.shape}\")\n",
    "print(f\"Backward output for SamplerQNN1: {sampler_qnn_weight_grad.shape}\")\n",
    "print(f\"Backward output for SamplerQNN2: {sampler_qnn_weight_grad2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3c5db-fe11-4f81-8acc-10837929e964",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations! You have completed the first steps towards the development of a QNN! While this may not have seemed like much, you have applied to neural network classes to a quantum circuit and taken the first steps towards understanding how these two methods differ. A major part of machine learning is understanding the first steps with regard to input data processing and expected output. These first steps were taken in this notebook, and you are free to go back and review what you did. You are also encouraged to play with the different inputs, weights, random seed, and explore situations of multiple observables along with custom interpreters! As mentioned, this is an vast field and is continuing to expand as more developments occur in the world of quantum computing and QML. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
